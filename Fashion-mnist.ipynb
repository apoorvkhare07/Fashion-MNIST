{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fashion MNIST is a drop-in replacement for the very well known, machine learning hello world, MNIST dataset. It has same number of training and test examples and the images have the same 28x28 size and there are a total of 10 classes/labels, you can read more about the dataset here : Fashion-MNIST\n",
    "\n",
    "#### In this I have tried an custom Neural Network on the above dataset. \n",
    "\n",
    "### Network Structure\n",
    "\n",
    "#### I have designed a two layer Neural Network, First layer will be the input layer having 784 input neurons and relu as the activation function. The second layer having 512 Neurons and activation function as relu and the last layer having 128 neurons and activation as softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "np.random.seed(12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 5s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 8us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 5s 1us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(images_path, labels_path):\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00392157 0.         0.         0.05098039 0.28627452 0.\n",
      " 0.         0.00392157 0.01568628 0.         0.         0.\n",
      " 0.         0.00392157 0.00392157 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01176471 0.\n",
      " 0.14117648 0.53333336 0.49803922 0.24313726 0.21176471 0.\n",
      " 0.         0.         0.00392157 0.01176471 0.01568628 0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02352941 0.         0.4        0.8\n",
      " 0.6901961  0.5254902  0.5647059  0.48235294 0.09019608 0.\n",
      " 0.         0.         0.         0.04705882 0.03921569 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.60784316 0.9254902  0.8117647  0.69803923\n",
      " 0.41960785 0.6117647  0.6313726  0.42745098 0.2509804  0.09019608\n",
      " 0.3019608  0.50980395 0.28235295 0.05882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00392157 0.         0.27058825\n",
      " 0.8117647  0.8745098  0.85490197 0.84705883 0.84705883 0.6392157\n",
      " 0.49803922 0.4745098  0.47843137 0.57254905 0.5529412  0.34509805\n",
      " 0.6745098  0.25882354 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.00392157 0.00392157 0.         0.78431374 0.9098039  0.9098039\n",
      " 0.9137255  0.8980392  0.8745098  0.8745098  0.84313726 0.8352941\n",
      " 0.6431373  0.49803922 0.48235294 0.76862746 0.8980392  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.7176471  0.88235295 0.84705883 0.8745098  0.89411765\n",
      " 0.92156863 0.8901961  0.8784314  0.87058824 0.8784314  0.8666667\n",
      " 0.8745098  0.9607843  0.6784314  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.75686276\n",
      " 0.89411765 0.85490197 0.8352941  0.7764706  0.7058824  0.83137256\n",
      " 0.8235294  0.827451   0.8352941  0.8745098  0.8627451  0.9529412\n",
      " 0.7921569  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.01176471 0.         0.04705882 0.85882354 0.8627451  0.83137256\n",
      " 0.85490197 0.7529412  0.6627451  0.8901961  0.8156863  0.85490197\n",
      " 0.8784314  0.83137256 0.8862745  0.77254903 0.81960785 0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02352941 0.\n",
      " 0.3882353  0.95686275 0.87058824 0.8627451  0.85490197 0.79607844\n",
      " 0.7764706  0.8666667  0.84313726 0.8352941  0.87058824 0.8627451\n",
      " 0.9607843  0.46666667 0.654902   0.21960784 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01568628 0.         0.         0.21568628 0.9254902\n",
      " 0.89411765 0.9019608  0.89411765 0.9411765  0.9098039  0.8352941\n",
      " 0.85490197 0.8745098  0.91764706 0.8509804  0.8509804  0.81960785\n",
      " 0.36078432 0.         0.         0.         0.00392157 0.01568628\n",
      " 0.02352941 0.02745098 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.92941177 0.8862745  0.8509804  0.8745098\n",
      " 0.87058824 0.85882354 0.87058824 0.8666667  0.84705883 0.8745098\n",
      " 0.8980392  0.84313726 0.85490197 1.         0.3019608  0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.24313726 0.5686275  0.8\n",
      " 0.89411765 0.8117647  0.8352941  0.8666667  0.85490197 0.8156863\n",
      " 0.827451   0.85490197 0.8784314  0.8745098  0.85882354 0.84313726\n",
      " 0.8784314  0.95686275 0.62352943 0.         0.         0.\n",
      " 0.         0.         0.07058824 0.17254902 0.32156864 0.41960785\n",
      " 0.7411765  0.89411765 0.8627451  0.87058824 0.8509804  0.8862745\n",
      " 0.78431374 0.8039216  0.827451   0.9019608  0.8784314  0.91764706\n",
      " 0.6901961  0.7372549  0.98039216 0.972549   0.9137255  0.93333334\n",
      " 0.84313726 0.         0.         0.22352941 0.73333335 0.8156863\n",
      " 0.8784314  0.8666667  0.8784314  0.8156863  0.8        0.8392157\n",
      " 0.8156863  0.81960785 0.78431374 0.62352943 0.9607843  0.75686276\n",
      " 0.80784315 0.8745098  1.         1.         0.8666667  0.91764706\n",
      " 0.8666667  0.827451   0.8627451  0.9098039  0.9647059  0.\n",
      " 0.01176471 0.7921569  0.89411765 0.8784314  0.8666667  0.827451\n",
      " 0.827451   0.8392157  0.8039216  0.8039216  0.8039216  0.8627451\n",
      " 0.9411765  0.3137255  0.5882353  1.         0.8980392  0.8666667\n",
      " 0.7372549  0.6039216  0.7490196  0.8235294  0.8        0.81960785\n",
      " 0.87058824 0.89411765 0.88235295 0.         0.38431373 0.9137255\n",
      " 0.7764706  0.8235294  0.87058824 0.8980392  0.8980392  0.91764706\n",
      " 0.9764706  0.8627451  0.7607843  0.84313726 0.8509804  0.94509804\n",
      " 0.25490198 0.28627452 0.41568628 0.45882353 0.65882355 0.85882354\n",
      " 0.8666667  0.84313726 0.8509804  0.8745098  0.8745098  0.8784314\n",
      " 0.8980392  0.11372549 0.29411766 0.8        0.83137256 0.8\n",
      " 0.75686276 0.8039216  0.827451   0.88235295 0.84705883 0.7254902\n",
      " 0.77254903 0.80784315 0.7764706  0.8352941  0.9411765  0.7647059\n",
      " 0.8901961  0.9607843  0.9372549  0.8745098  0.85490197 0.83137256\n",
      " 0.81960785 0.87058824 0.8627451  0.8666667  0.9019608  0.2627451\n",
      " 0.1882353  0.79607844 0.7176471  0.7607843  0.8352941  0.77254903\n",
      " 0.7254902  0.74509805 0.7607843  0.7529412  0.7921569  0.8392157\n",
      " 0.85882354 0.8666667  0.8627451  0.9254902  0.88235295 0.84705883\n",
      " 0.78039217 0.80784315 0.7294118  0.70980394 0.69411767 0.6745098\n",
      " 0.70980394 0.8039216  0.80784315 0.4509804  0.         0.47843137\n",
      " 0.85882354 0.75686276 0.7019608  0.67058825 0.7176471  0.76862746\n",
      " 0.8        0.8235294  0.8352941  0.8117647  0.827451   0.8235294\n",
      " 0.78431374 0.76862746 0.7607843  0.7490196  0.7647059  0.7490196\n",
      " 0.7764706  0.7529412  0.6901961  0.6117647  0.654902   0.69411767\n",
      " 0.8235294  0.36078432 0.         0.         0.2901961  0.7411765\n",
      " 0.83137256 0.7490196  0.6862745  0.6745098  0.6862745  0.70980394\n",
      " 0.7254902  0.7372549  0.7411765  0.7372549  0.75686276 0.7764706\n",
      " 0.8        0.81960785 0.8235294  0.8235294  0.827451   0.7372549\n",
      " 0.7372549  0.7607843  0.7529412  0.84705883 0.6666667  0.\n",
      " 0.00784314 0.         0.         0.         0.25882354 0.78431374\n",
      " 0.87058824 0.92941177 0.9372549  0.9490196  0.9647059  0.9529412\n",
      " 0.95686275 0.8666667  0.8627451  0.75686276 0.7490196  0.7019608\n",
      " 0.7137255  0.7137255  0.70980394 0.6901961  0.6509804  0.65882355\n",
      " 0.3882353  0.22745098 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15686275\n",
      " 0.23921569 0.17254902 0.28235295 0.16078432 0.13725491 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9dc410cfd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9dc6bbc0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.4755 - acc: 0.8272\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.3579 - acc: 0.8680\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.3255 - acc: 0.8788\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.3015 - acc: 0.8871\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.2848 - acc: 0.8921\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.2714 - acc: 0.8978\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.2598 - acc: 0.9023\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.2512 - acc: 0.9057\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.2393 - acc: 0.9086\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.2323 - acc: 0.9118\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 20s 325us/step - loss: 0.2243 - acc: 0.9139\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 22s 360us/step - loss: 0.2156 - acc: 0.9173\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 22s 370us/step - loss: 0.2118 - acc: 0.9186\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 22s 373us/step - loss: 0.2058 - acc: 0.9223\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.2002 - acc: 0.9239\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.1959 - acc: 0.9251\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 23s 384us/step - loss: 0.1893 - acc: 0.9284\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 23s 382us/step - loss: 0.1870 - acc: 0.9291\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.1816 - acc: 0.9316\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 23s 383us/step - loss: 0.1758 - acc: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9dc63309b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3539742024064064\n",
      "Test accuracy: 0.8924\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
