{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import  Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "np.random.seed(12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = 'train-images_mnist.idx3-ubyte'\n",
    "train_fmnist = 'train-images_fashion-idx3-ubyte'\n",
    "train_mnist_label = 'train-labels_mnist.idx1-ubyte'\n",
    "train_fmnist_label = 'train-labels_fashion-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-labels_mnist.idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-504d82c8ae98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mnist_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflbl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">II\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-labels_mnist.idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "with open(train_mnist_label, 'rb') as flbl:\n",
    "    magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open(train_mnist, 'rb') as fimg:\n",
    "    magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_y  = keras.utils.np_utils.to_categorical(lbl ,  10  )\n",
    "train_x = np.asarray(img)\n",
    "train_y = np.asarray(train_y) \n",
    "print (train_y.shape)\n",
    "print (train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x , [60000,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.reset_states() \n",
    "\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3) ,  input_shape = ( 26, 26, 64) , name = \"con1\") ) \n",
    "    model.add(Activation('relu' , name = \"act1\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool1\") )\n",
    "\n",
    "    model.add(Convolution2D(32, (3, 3), name = \"con2\"))\n",
    "    model.add(Activation('relu', name = \"act2\" ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool2\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "con1 (Conv2D)                (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "con2 (Conv2D)                (None, 10, 10, 32)        18464     \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8010      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 63,402\n",
      "Trainable params: 63,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 32s 525us/step - loss: 2.0737 - acc: 0.8105\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 32s 526us/step - loss: 0.1825 - acc: 0.9575\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.1137 - acc: 0.9718\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 36s 603us/step - loss: 0.0829 - acc: 0.9787\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.0667 - acc: 0.9825\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 35s 582us/step - loss: 0.0566 - acc: 0.9853\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 34s 565us/step - loss: 0.0483 - acc: 0.9871\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 0.0430 - acc: 0.9889\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.0392 - acc: 0.9897\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0357 - acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2d09bb080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( train_x , train_y  , batch_size= batch_size ,   epochs = 10,  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_fmnist_label , 'rb') as flbl:\n",
    "    magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "    fashion_lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open(train_fmnist, 'rb') as fimg:\n",
    "    magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    fashion_img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    \n",
    "inds = fashion_lbl.argsort()\n",
    "\n",
    "fashion_img= fashion_img[inds]\n",
    "fashion_lbl= fashion_lbl[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_y  = keras.utils.np_utils.to_categorical(fashion_lbl ,  10  )\n",
    "train_x = np.asarray(fashion_img)\n",
    "train_y = np.asarray(train_y) \n",
    "print (train_y.shape)\n",
    "print (train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc26e62ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_x[0, :].reshape((28, 28)))\n",
    "train_x = np.reshape(train_x , [60000,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 4.5797 - acc: 0.6111\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 2.5539 - acc: 0.7407\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 2.2834 - acc: 0.7612\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 1.7018 - acc: 0.7998\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.4604 - acc: 0.8814\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.3925 - acc: 0.8884\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 0.3506 - acc: 0.8958\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.3210 - acc: 0.9008\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.3029 - acc: 0.9046\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.2846 - acc: 0.9091\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.2726 - acc: 0.9121\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.2614 - acc: 0.9149\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.2542 - acc: 0.9169\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.2478 - acc: 0.9187\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.2404 - acc: 0.9206\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.2370 - acc: 0.9217\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.2325 - acc: 0.9232\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.2294 - acc: 0.9251\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 21s 346us/step - loss: 0.2266 - acc: 0.9258\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.2218 - acc: 0.9264\n"
     ]
    }
   ],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.reset_states() \n",
    "\n",
    "fashion_model.add(Convolution2D( 64  , (3, 3) , input_shape = train_x[0].shape))  \n",
    "fashion_model.add(Activation('relu'))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(10))\n",
    "fashion_model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "fashion_model.reset_states( )\n",
    "\n",
    "fashion_model.load_weights(\"model_weights.h5\",by_name=True)\n",
    "\n",
    "fashion_model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "fashion_history = fashion_model.fit( train_x , train_y , batch_size= 32, epochs = 20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.reset_states() \n",
    "\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3) ,  input_shape = ( 26, 26, 64) , name = \"con1\") ) \n",
    "    model.add(Activation('relu' , name = \"act1\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool1\") )\n",
    "\n",
    "    model.add(Convolution2D(32, (3, 3), name = \"con2\"))\n",
    "    model.add(Activation('relu', name = \"act2\" ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool2\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "con1 (Conv2D)                (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "con2 (Conv2D)                (None, 10, 10, 32)        18464     \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                8010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 63,402\n",
      "Trainable params: 63,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in fashion_model.layers:\n",
    "    if 'con' in layer.name:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "con1 (Conv2D)                (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "con2 (Conv2D)                (None, 10, 10, 32)        18464     \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                8010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 63,402\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 55,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.load_weights(\"model_weights.h5\",by_name=True)\n",
    "\n",
    "fashion_model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "fashion_history = fashion_model.fit( train_x , train_y , batch_size= 32, epochs = 20, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
